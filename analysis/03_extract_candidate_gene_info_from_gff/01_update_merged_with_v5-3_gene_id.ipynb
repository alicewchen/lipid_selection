{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Chlamy annotation v5.3 version of `merged` in data/intermediate_data_02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import relevant files\n",
    "\n",
    "#### Transcipt id conversion key\n",
    "Conversion key file path : `/scratch/research/projects/chlamydomonas/lipid_selection/data/gene_name_conversion/ChlamydomonasTranscriptNameConversionBetweenReleases.Mch12b.txt.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/scratch/research/projects/chlamydomonas/lipid_selection/data/gene_name_conversion/ChlamydomonasTranscriptNameConversionBetweenReleases.Mch12b.txt.gz'\n",
    "\n",
    "genome_version = '5.3.1'\n",
    "with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as z:\n",
    "    conversion_key = pd.read_csv(z, delimiter = r\"\\s+\",skiprows = 1, na_values = \"--\")\n",
    "    conversion_key.columns = ['5.5', '3.1', 'Genbank', '4', '4.3', 'u5', 'u9', '5.3.1']\n",
    "    conversion_key = conversion_key[['5.5', genome_version ]].dropna()\n",
    "\n",
    "#sort conversion_key by v5.5 transcript id's\n",
    "conversion_key = conversion_key.sort_values(by = ['5.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  5.5               5.3.1\n",
      "0  Cre01.g000017.t1.1               g2.t1\n",
      "1  Cre01.g000033.t1.1               g3.t1\n",
      "2  Cre01.g000050.t1.1  Cre01.g000050.t1.3\n",
      "3  Cre01.g000100.t1.1  Cre01.g000100.t1.3\n",
      "4  Cre01.g000150.t1.2  Cre01.g000150.t1.2\n",
      "5  Cre01.g000200.t1.1  Cre01.g000200.t1.3\n",
      "6  Cre01.g000250.t1.2  Cre01.g000250.t1.2\n",
      "7  Cre01.g000300.t1.1  Cre01.g000300.t1.3\n",
      "8  Cre01.g000350.t1.1  Cre01.g000350.t1.3\n",
      "9  Cre01.g000400.t1.2  Cre01.g000400.t1.2\n"
     ]
    }
   ],
   "source": [
    "print(conversion_key[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `data/intermediate_data_02/merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"../../data/intermediate_data_02/merged.csv\")\n",
    "merged = merged.sort_values(by = ['transcript_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transcript_id', 'num_detected', 'num_sampled', 'proportion', 'source',\n",
      "       'annotation_version', 'gene_id', 'gene_symbol', 'pathway_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Binary search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinarySearch(lys, val):\n",
    "    \n",
    "    '''requires re'''\n",
    "    \n",
    "    '''This function returns the position of the element in the list lys that contains the string pattern lys. If no match \n",
    "    \n",
    "    Usage: lys = list of strings to search through; val = string pattern to search for\n",
    "    \n",
    "    Warning: This function only works when the beginning of the string matches val'''\n",
    "        \n",
    "    first = 0\n",
    "    last = len(lys)-1\n",
    "    index = -1\n",
    "    \n",
    "    \n",
    "    p = re.compile(re.escape(val))\n",
    "    \n",
    "    \n",
    "    while (first <= last) and (index == -1):\n",
    "        mid = round((first+last)/2)\n",
    "        \n",
    "        index_list = sorted([lys[mid],val])\n",
    "        \n",
    "        if p.match(lys[mid]):\n",
    "            index = mid\n",
    "        else:\n",
    "            \n",
    "            if index_list.index(val)<index_list.index(lys[mid]):\n",
    "                last = mid -1\n",
    "                \n",
    "            else:\n",
    "                first = mid +1\n",
    "                \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "-1\n",
      "-1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Test cell\n",
    "\n",
    "#When matching string exists\n",
    "test_list = list(conversion_key['5.5'][:10])\n",
    "value = 'Cre01.g000150.t1.2'\n",
    "print(BinarySearch(test_list, value))\n",
    "\n",
    "#When matching string does not exist\n",
    "value = 'Does not exist'\n",
    "print(BinarySearch(test_list, value))\n",
    "\n",
    "#When matching string is in the middle of an existing string\n",
    "value = \"g000250\"\n",
    "print(BinarySearch(test_list, value))\n",
    "\n",
    "#When matching string starts an existing string\n",
    "value = \"Cre01.g000150\"\n",
    "print(BinarySearch(test_list, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.791561603546143 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "transcript_id_v5_3_1 =[]\n",
    "\n",
    "for transcript in list(merged.transcript_id):    \n",
    "    \n",
    "    \n",
    "    index = BinarySearch(list(conversion_key['5.5']), transcript)\n",
    "                         \n",
    "    if index == -1: transcript_id_v5_3_1.append(None)\n",
    "                         \n",
    "    else: transcript_id_v5_3_1.append(conversion_key.loc[index, '5.3.1'])\n",
    "        \n",
    "t1 = time.time()\n",
    "print(t1-t0,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of v5.5 transcripts that does not have a matching v5.3.1 transcript id:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of v5.5 transcripts that does not have a matching v5.3.1 transcript id: \", transcript_id_v5_3_1.count(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 JumpSearch method\n",
    "\n",
    "Search took ~18s. This is slower than the binary search method."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "def JumpSearch (lys, val):\n",
    "    \n",
    "    '''This function returns the position of the element in the list lys that contains the string pattern lys. If no match \n",
    "    \n",
    "    Usage: lys = list of strings to search through; val = string pattern to search for\n",
    "    \n",
    "    Warning: This function only works when the beginning of the string matches val'''\n",
    "    \n",
    "    length = len(lys)\n",
    "    jump = int(math.sqrt(length))\n",
    "    left, right = 0, 0\n",
    "    index_list = sorted([lys[left],val,lys[right]])\n",
    "    p = re.compile(re.escape(val))\n",
    "    while left < length and index_list.index(lys[left]) <= index_list.index(val):\n",
    "        right = min(length - 1, left + jump)\n",
    "        index_list = sorted([lys[left],val,lys[right]])\n",
    "        if index_list.index(lys[left]) <= index_list.index(val) and index_list.index(lys[right]) >= index_list.index(val):\n",
    "            break\n",
    "        left += jump;\n",
    "        \n",
    "    if left >= length or index_list.index(lys[left]) > index_list.index(val):\n",
    "        return -1\n",
    "    right = min(length-1, right)\n",
    "    i = left\n",
    "    #index_list = sorted([lys[i],val])\n",
    "    while i <= right:\n",
    "        index_list = sorted([lys[i],val])\n",
    "        #print(p.search(lys[i]), lys[i])\n",
    "        if p.match(lys[i]):\n",
    "            return i\n",
    "        i += 1\n",
    "      \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t0 = time.time()\n",
    "transcript_id_v5_3_1 =[]\n",
    "\n",
    "for transcript in list(merged.transcript_id):    \n",
    "    \n",
    "    \n",
    "    index = JumpSearch(list(conversion_key['5.5']), transcript)\n",
    "                         \n",
    "    if index == -1: transcript_id_v5_3_1.append(None)\n",
    "                         \n",
    "    else: transcript_id_v5_3_1.append(conversion_key.loc[index, '5.3.1'])\n",
    "        \n",
    "t1 = time.time()\n",
    "print(t1-t0, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create v5.3.1 annotation version of merged.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['transcript_id_v5.3.1']=  transcript_id_v5_3_1\n",
    "merged.to_csv('../../data/intermediate_data_from_gff/merged_v5_3_1.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
